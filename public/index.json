[{"authors":["admin"],"categories":null,"content":"Brain damaged brain student writing about methodological and statistical issues in cognitive neuroscience, as well as other related topics. If I feel inclined I might write more technical posts and if you\u0026rsquo;re real unlucky there might even slip in some fiction book reviews. I will only post about my mental fatigue when I have the energy.\n","date":1586476800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1586476800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Brain damaged brain student writing about methodological and statistical issues in cognitive neuroscience, as well as other related topics. If I feel inclined I might write more technical posts and if you\u0026rsquo;re real unlucky there might even slip in some fiction book reviews.","tags":null,"title":"Jonathan Ö. Rittmo","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Tutorials on my upcoming R package for single case research will be uploaded shortly.","tags":null,"title":"","type":"docs"},{"authors":[],"categories":[],"content":"\r\r…external perception is an internal dream which proves to be in harmony with external things; and instead of calling hallucination a false external perception, we must call external perception true hallucination.\n\rThe above quote from 19th century philospher Hippolyte Taine captures the elusive question: what do we mean by ‘reality’? If you recognise the featured image, you have probably come across the game Hellblade: Senuas Sacrifice, where you follow Senua battle the crackling of her reality. The game was critically acclaimed for depicting the subjective experience of psychosis.\nThe game makers worked closely with neuroscientists, one of which was Paul Fletcher, a professor at Cambridge who has devoted much of his career to understanding the mechanisms of psychosis. I attended a talk of his a couple of months ago where he mentioned the game and I immediately got excited. Due to the current circumstances I had the chance to play through it this weekend - and it was a ride. I know my last post said I was gonna write more about power curves but after playing the game I couldn’t resist a small post on this subject. A version of Fletcher’s talk, in which he conveys the keystone ideas from his 20 years of research is available here.\nTo get as immersed as possible I played the game in complete darkness, with noise cancelling headphones and the volume high (which I sincerly recommend, since they put a lot of effort in to the audio). I nearly completed it in one sitting which was prefereable to screen off as much of my world as possible and delve into that of Senua’s psychosis. In this post I am going to go through some of the ideas they based the game on ‒ which really shines through in both script and experience.\nThe term ‘psychosis’ is not uncontroversial. If we define it loosely as losing contact with reality, it is easy to see why. Because what makes our healthy perception real? Fletcher makes the case that we are all a bit out of touch with reality. Most people simply hallucinate true events.\nThis might be difficult to grasp. But since your brain is encased in a skull and has no direct contact with the outside world it must create a predictive model of it. Hence, Fletcher argues, psychotic illness is just a small variation in normal perceptive processing.\nWhy do we have a brain? A fundemental fact of biological life is that the genes that most easily continue to exist tend to do just that. In a complex and noisy world, a machine that can make predictions about it would benefit any organism.\nIn a sense then, our brain is like a scientist, trying to draw inferences and making predictions from incomplete data. To do this one utilises expectations. Information from previous experiences that make our predictions more or less likely. If our predictions do not match the external world we must update them (in science and in life) with our given feedback. One can imagine the power of such device just by looking at how science has benefitted society.\nThis creates loops of predictions, inputs and prediction errors that integrate to form a stable perception. It is a breakdown of these integration processes that causes the psychotic state, Fletcher argues.\nPerception has two foundations: input and predictions. Take a look at the hollow mask illusion:\nIn the bottommost image we see a convex surface. The facial features however, make us expect it to be concave. Therefore it appears as such. It is easy to imagine how more abstract ideas could shape perceived input as well. For example, facial expressions being interpreted differently depending on contexts.\nThis mechanism can also be additive. Take the Kanizsa triangle, for example, where it is almost impossible not to see a white triangle laying over the other shapes even though it is not there:\nSo, expectations create perceptions. Fletcher describes a system that tries to maintain stability between predictions and input. To best align your internal world with the external. This happens at multiple levels ‒ from abstract (expressions) to concrete (Kanizsa triangle). Below is my interpretation of this system, W = weight.\nYou can see that a balance between input and predictions must be maintained. If one gets too weighted it affects perception. For example if the input is cut off, predictions get an overbalance and hence your mind takes control of your perception and hallucinations might be induced - which often happen during e.g. sensory deprivation.\nFletcher also mention that traumatic experiences, such as child abuse, could cause abstract predictions being unreasonably weighted. E.g. predicting low self worth could in a downstream manner affect how you see and interpret aspects of the world. Perhaps it would seem more ill-willed. Similarily such prediction might cause additive percepts of, for example, derogatory voices. This would correspond to the two cornerstones of pyschosis, delusion and hallucination respectively.\nPsychotic traits is, by this model, hence formed by too strong predictions. But strong predictions can also aid your perception. Imagine looking at a painting in your home during night. Since you know it, it’s easier to see the contours, right? If you don’t believe me, try to discern the image below:\nNot very easy, right? I, however, cannot not see myself as a kid:\nGiven Fletcher’s model, hallucination prone individuals would thus be better at these types of tasks (given previous exposure, so that they have something to expect). This was also found by him and colleagues.\nFurther evidence both for and against the model is reviewed in the talk. But I do not want to spoil all the fun and advise you to take a look at it.\nI should also make it clear that Fletcher does not claim that this model paint a complete picture. I for one am a bit sceptical about the hierarchical structure of the integration processes. However, if you are interested in this stuff (who wouldn’t be interested in what reality is, eh?) Fletcher makes a compelling case. Playing through Hellblade after you’ve watched the talk makes it even more compelling as the ideas are communicated by experiencing them ‒ which is both thought provoking and generates an understanding and compassion for the people suffering from this. (You could also use drugs, but I’d give Hellblade a go first).\n","date":1586563200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586611974,"objectID":"090ed38b0c6e87806dc384926f07db2b","permalink":"/post/perception-and-psychosis/","publishdate":"2020-04-11T00:00:00Z","relpermalink":"/post/perception-and-psychosis/","section":"post","summary":"…external perception is an internal dream which proves to be in harmony with external things; and instead of calling hallucination a false external perception, we must call external perception true hallucination.","tags":[],"title":"Perception, Psychosis and Hellblade","type":"post"},{"authors":["Jonathan Ö. Rittmo","Rickard Carlsson","Pierre Gander","Robert Lowe"],"categories":null,"content":"","date":1586476800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586476800,"objectID":"3c352b4d865a8c2f89fdd5d6674e0ceb","permalink":"/publication/vic_value/","publishdate":"2020-04-10T00:00:00Z","relpermalink":"/publication/vic_value/","section":"publication","summary":"The findings of differential outcomes training procedures in controlled stimulus response learning settings have been explained through theorizing two processes of response control. These processes concern: i) a stimulus-response route, and, ii) an outcome expectancy route through which valuations of stimuli (typically auditory or visual) may be represented. Critically, under certain contingencies of learning, the interaction of these two processes enables a transfer of knowledge. Transfer is hypothesized to occur via implicit inference for response selection given novel stimulus-response pairings. In this article, we test this transfer of knowledge, previously only examined in individual settings, in novel social settings. We find that participants are able to achieve transfer of knowledge and suggest they achieve this through vicariously learning the differential valuations of stimuli made by the (confederate) ‘other’ involved in the task. We test this effect under two experimental conditions through manipulation of the information made available to participants observing the confederate other’s choices. The results of EEG recordings are, additionally, evaluated and discussed in the context of social signalling and emotional and cognitive empathy. We also consider implications for clinical and technological social learning settings.","tags":["affect","differential outcomes training","inference","knowledge transfer"],"title":"Vicarious Value Learning: Knowledge Transfer through Affective Processing on a Social Differential Outcomes Task (accepted with revisions)","type":"publication"},{"authors":[],"categories":[],"content":"\r\r\r\rAs the image above (probably abused by me) clearly states: “the abuse of power comes as no surprise”. Whether intentional or not, ingorance of a priori power calculations have been prominent in psychology and related fields.\nBut this is not surprising, because it is difficult to grasp what a power calculation actually is. In this post I will walk through some of the basic calculations behind deriving the power function for a paired samples z-test analytically (that is obtaining an exact mathematical function) and how you can calculate power for an independent two sample t-test, by simulations in R. Hopefully this will show that the basic concepts of power calculations and power curves actually are quite easy! So here goes:\nThe power function for a hypothesis test is defined as the following:\n\\[power(\\theta) =\\mathbb{P}[\\text{reject} \\: H_0 \\: \\text{for a given} \\: \\theta]\\]\nWhere \\(\\theta\\) is a given effect size, \\(\\mathbb{P}\\) probability and \\(H_0\\) the null hypothesis. In more general terms it is defined (the vertical bar is read “given”):\n\\[power =\\mathbb{P}[\\text{reject} \\: H_0\\: | \\: H_1 \\: \\text{is true}]\\]\nSay that we want to test whether a medication has had some effect on a sample (we measure a continuous dependent variable on the same individuals before and after treatment) and we assume that we know the population standard deviation. If \\(\\overline{D}\\) is the average difference between the observations, for each individual then \\(\\overline{D} \\sim N(\\mu, \\sigma^2)\\), meaning that \\(\\overline{D}\\) follows the normal distribution with some population mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)). Standardising \\(\\overline{D}\\) by centering it around 0 (since we are talking about a difference it is already centered around 0 though) and dividing by the standard error we would have an entitiy that follows the standard normal distribution:\n\\[\\frac{\\overline{D}-0}{{{\\sigma}_D}/{\\sqrt{n}}}\\sim Z\\]\nWhere \\(\\overline{D}\\) is the average of the differences between the two measurement time points and \\({\\sigma}_D\\) the population standard deviation and hence \\({{\\sigma}_D}/{\\sqrt{n}}\\) the standard error and thus, if we input real values we would get a z-value. The null and alternative hypotheses for this test are \\(H_0:\\: \\mu_D \\: = \\: 0\\) and \\(H_1:\\: \\mu_D \\: \\neq \\: 0\\) where \\(\\mu_D\\) is estimated by \\(\\overline{D}_n\\).\nIf we set \\(\\alpha\\:=\\:0.05\\) (i.e. \\(\\mathbb{P}\\)[reject \\(H_0\\) | \\(H_0\\) is true]\\(\\:=\\:0.05\\)) our critical z-value would be \\(z_{(0.05/2) }=\\) \\(\\pm\\) 1.96. If you are unfamilliar with critical values, have a look at the density plot below.\nAll observed z-values that fall above the upper or below the lower critical cutoff values are considered significant at the \\(\\alpha \\: = \\: 0.05\\) level. Now suppose that \\(\\mu_D \\: \\neq \\: 0\\), i.e. \\(\\mu_D =\\) \\(\\theta\\). Then we get the power by calculating:\n\\[\\mathbb{P}[1.96 \u0026lt; Z \u0026lt; -1.96 \\; | \\; \\mu_D =\\theta]\\]\nSince \\(\\frac{\\overline{D}_n-0}{{{\\sigma}_D}/{\\sqrt{n}}}\\sim Z\\) we’ll write:\n\\[\\mathbb{P}[1.96 \u0026lt; \\frac{\\overline{D}_{n}-0}{{{\\sigma}_D}/{\\sqrt{n}}} \u0026lt; -1.96 \\; | \\; \\mu_D =\\theta]\\]\nWe’ll subtract and add \\(\\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}\\), i.e. a neutral operation:\n\\[\\mathbb{P}[1.96 \u0026lt; \\frac{\\overline{D}_{n}\\:-\\:0\\:-\\:\\theta\\:+\\:\\theta}{{{\\sigma}_D}/{\\sqrt{n}}} \u0026lt; -1.96 \\; | \\; \\mu_D =\\theta]\\]\nAnd then move \\(+\\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}\\) to the other sides of the inequalities (be careful with the signs!):\n\\[\\mathbb{P}[1.96\\: - \\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}\u0026lt; \\frac{\\overline{D}_{n}\\:-\\:\\theta}{{{\\sigma}_D}/{\\sqrt{n}}} \u0026lt; -1.96 -\\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}} \\; | \\; \\mu_D =\\theta]\\]\nThen we have:\n\\[power(\\theta) = \\mathbb{P}[1.96\\: - \\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}\u0026lt; Z \u0026lt; -1.96 -\\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}]\\]\nWhich is the same as:\n\\[power(\\theta) = \\mathbb{P}[Z \u0026lt; -1.96 -\\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}] + \\mathbb{P}[Z \u0026gt; 1.96\\: - \\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}]\\]\nNote that\n\\[\\mathbb{P}[Z \u0026gt; 1.96\\: - \\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}]\\]\nalso can be written\n\\[1 \\: - \\: \\mathbb{P}[Z \u0026lt; 1.96\\: - \\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}]\\]\nSo now we can write our power function for this test:\n\\[power(\\theta) = \\mathbb{P}[Z \u0026lt; -1.96 +\\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}] + 1 \\: - \\: \\mathbb{P}[Z \u0026lt; 1.96\\: - \\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}]\\]\nThe notation \\(\\mathbb{P}[Z \u0026lt; z]\\) is usually written \\(N(z)\\) and denotes the area under the cumulative distribution function up til the value of \\(z\\).\nThis became much more technical than what I imagined when I started out with this post. I might have to push my amateur adventures in 3D visualisation to the next post! Anyway, now we have:\n\\[power(\\theta) = N(-1.96 +\\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}}) + 1 - N(1.96\\: - \\frac{\\theta}{{{\\sigma}_D}/{\\sqrt{n}}})\\]\nIf we assume \\(\\sigma_D=1\\) and some sample size this will give us a single value for each \\(\\theta\\) we put in. We can easily calculate this in R and plot the power against possible values of \\(\\theta\\) – this is what is known as a power curve. If we instead are interested in seeing how sample size affect power, we hold \\(\\theta\\) fixed and vary n. Below I show the code for for how to calculate and draw the power curve via this function in R for a specified sample size of \\(n=25\\). In the interactive graph below though, you can adjust the sample size yourself and see how that affects power.\npower_data \u0026lt;- data.frame(theta = seq(from = -1.2, to = 1.2, length.out = 100)) %\u0026gt;% # Create a data frame with a variabl of various theta\rmutate(power = pnorm(-1.96-theta*sqrt(25)) + (1-pnorm(1.96-theta*sqrt(25)))) # Add a variable that for each theta gives us power, according to the power function above\rggplot(power_data, aes(x= theta, y=power)) + # Plot power over theta\rgeom_line(size=1) +\rgeom_hline(yintercept = 0.05, linetype =\u0026quot;dashed\u0026quot;, color = \u0026quot;darkblue\u0026quot;) +\rgeom_vline(xintercept = 0) +\rxlab(expression(paste(theta))) +\rylab(\u0026quot;Power\u0026quot;) +\rannotate(geom = \u0026quot;text\u0026quot;, x = 0.3, y = 0.08,\rlabel = \u0026quot;alpha\u0026quot;,\rparse = T,\rcolor = \u0026quot;darkblue\u0026quot;,\rsize = 5) +\rtheme_classic()\r\r\r{\"x\":{\"url\":\"/post/primary-concepts/index_files/figure-html//widgets/widget_powercurve.html\",\"options\":{\"xdomain\":\"*\",\"allowfullscreen\":false,\"lazyload\":false}},\"evals\":[],\"jsHooks\":[]}\rAs the true effect becomes bigger in absolute values, power goes to 100%. Optimally one would want a power function that wasn’t curved but instead always rejected \\(H_0\\) whenever it was false, how small the effect may be. I.e. we would want a power function that fulfills:\n\\[\\begin{equation} power =\\mathbb{P}[\\text{reject} \\: H_0 \\: | \\: \\text{any} \\: \\theta \\neq 0] = 1\r\\tag{1}\r\\end{equation}\\]\nand\n\\[\\begin{equation} power =\\mathbb{P}[\\text{reject} \\: H_0 \\: | \\: \\theta = 0] = 0\r\\tag{2}\r\\end{equation}\\]\nHowever, tests that fufill these are in practice difficult (if not impossible) to find and we must compromise. For example, equation (2) tells us that we do not ever want to reject the null hypothesis if it is in fact true. The probability of rejecting the null when the null is true is what we usually refer to as our α-level which we most commonly set to \\(0.05\\) in psychology, i.e. it is the probbility of a Type I error (falsely rejecting the null hypothesis). This compromise can be seen in the power curve above. Additionally, the smaller θ gets, the more difficult the effect is to detect, because the areas under the distribution function shrink.\nWhen we now know what a power curve is and how it can be derived analytically for a given test, it might be worth mentioning how one can approximate power numerically with simulations. I am not going to use the paired example as I did above, because that requires us to assume some correlation between the measurements. I am going to show the easiest example of simulating power for a t-test between two independent groups, i.e. we assume independence between observations.\nThe basic concept behind it is fairly simple, we draw one sample from a normal distributions with a mean of 0 and we draw one sample from a normal distribution with a mean of θ. We then run a t-test to compare the mean differences between the samples to see obtain a p-value. We do this a couple of times and save the p-values for every test. Then we divide the number of significant p-values (p-values \u0026lt; 0.05 in this case) on the total number of tests run and the ratio that we obtain is the power. That is, the power is the number of significant tests, divided by the total number of simulations. The more simulations run, the closer our numerical solution will be to the analytical. Look at the code below.\n\rpower_sim \u0026lt;- function (nsim, theta, n1, n2) {\rsim_mat \u0026lt;- cbind(matrix(rnorm(n1*nsim, mean = theta, sd=1), nrow = nsim,\rncol = n1),\rmatrix(rnorm(n2*nsim, mean = 0, sd=1), nrow = nsim,\rncol = n2))\rp_val \u0026lt;- apply(X = sim_mat, MARGIN = 1, function(x) t.test(x = x[1:n1], y = x[(n1+1):(n1+n2)],\ralternative = \u0026quot;two.sided\u0026quot;,\rpaired = FALSE)[[\u0026quot;p.value\u0026quot;]]\r)\rpower \u0026lt;- sum(p_val \u0026lt; 0.05)/length(p_val)\rreturn(power)\r}\r\rSay that we want to see what the power curve would look like over different values of θ, as we did above. We then need to run the simulations for every specified value of θ. This is most easily done in a loop, but you can think of it as if we are running the function above for every θ that are of interest, for example like this:\npower_sim(nsim = 50, theta = 0.5 , n1 = 25, n2 = 25)\rpower_sim(nsim = 50, theta = 1.0 , n1 = 25, n2 = 25)\rpower_sim(nsim = 50, theta = 1.5 , n1 = 25, n2 = 25)\rDoing it in a loop however requires a lot less code, so we specify a θ vector, with every value that we are interested in and iteratively run the power simulation function we created for each of those values. The code below does this and then plot the obtained power values over θ for 50 simulations.\n\rtheta \u0026lt;- seq(from = -1.2, to = 1.2, length.out = 50) # Here we specify 50 different values of theta\rpower \u0026lt;- 0 # We need to define an object outside of the loop to be able to iteratively save the power calculations\rfor (i in 1:length(theta)) { # This is the loop, which runs the code below and saves the power iteratively\rpower[i] \u0026lt;- power_sim(nsim = 50, theta[i], n1 = 25, n2 = 25)\r}\rpower_data \u0026lt;- as.data.frame(cbind(power, theta)) # Putting the theta vector and power vector into a data frame ggplot(power_data, aes(x= theta, y=power)) + # Plotting power over theta, just as we did analytically\rgeom_line(size=1) +\rgeom_hline(yintercept = 0.05, linetype =\u0026quot;dashed\u0026quot;, color = \u0026quot;darkblue\u0026quot;) +\rgeom_vline(xintercept = 0) +\rxlab(expression(paste(theta))) +\rylab(\u0026quot;Power\u0026quot;) +\rannotate(geom = \u0026quot;text\u0026quot;, x = 0.3, y = 0.08, label = \u0026quot;alpha\u0026quot;, parse = T, color = \u0026quot;darkblue\u0026quot;, size = 5) +\rtheme_classic()\rAs can be seen, the general pattern is similar to the analytical solution. But since we only ran 50 simulations for every parameter combination we won’t get very precise estimations. So let’s amp it up to 10,000 simulations:\n\rtheta \u0026lt;- seq(from = -1.2, to = 1.2, length.out = 50) power \u0026lt;- 0 for (i in 1:length(theta)) { power[i] \u0026lt;- power_sim(nsim = 10000, theta[i], n1 = 25, n2 = 25)\r}\rpower_data \u0026lt;- as.data.frame(cbind(power, theta)) ggplot(power_data, aes(x= theta, y=power)) + # Plotting power over theta, just as we did analytically\rgeom_line(size=1) +\rgeom_hline(yintercept = 0.05, linetype =\u0026quot;dashed\u0026quot;, color = \u0026quot;darkblue\u0026quot;) +\rgeom_vline(xintercept = 0) +\rxlab(expression(paste(theta))) +\rylab(\u0026quot;Power\u0026quot;) +\rannotate(geom = \u0026quot;text\u0026quot;, x = 0.3, y = 0.08, label = \u0026quot;alpha\u0026quot;, parse = T, color = \u0026quot;darkblue\u0026quot;, size = 5) +\rtheme_classic()\r\rNow, this looks more like it! This approach is a useful tool for a priori power calculations when an anlytical solution is too difficult (sometimes it’s even impossible) to find. But naturally, when our designs get more complex it will be more difficult to calculate power either analytically or with simulations. But I hope that this post at least showed that you don’t have to be a mathematician to start out with your a priori power calcs!\nNext up: amateur adventures in 3D visualisation of multivariable/variate power curves!\n","date":1585958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586007174,"objectID":"12f4881722b4c1d5f985a21946b6a061","permalink":"/post/primary-concepts-of-power-curves/","publishdate":"2020-04-04T00:00:00Z","relpermalink":"/post/primary-concepts-of-power-curves/","section":"post","summary":"As the image above (probably abused by me) clearly states: “the abuse of power comes as no surprise”. Whether intentional or not, ingorance of a priori power calculations have been prominent in psychology and related fields.","tags":[],"title":"Primary Concepts of Power Curves","type":"post"},{"authors":[],"categories":["research"],"content":"Key concepts:\n Power = the probability of finding an effect if the effect is true  Have you ever been at a psychology stats lecture listening to your teacher rambling about \u0026ldquo;power\u0026rdquo;, talking about its importance for your experiment to yield a significant result but without really explaining the \u0026ldquo;why\u0026rdquo; of it all? Well, so have I. It is usually easy enough to grasp that low power = bad, high power = good - it\u0026rsquo;s name kind of gives it away. And given that significance is often treated as the holy grail in psychology most students would want a high probability to obtain it. The advice is often to calculate a sample size based on some previous (or just predicted) effect. However, for a two group experiment with a between group design and expected medium effect (which arguably could be seen as optimistic) we would need 64 participants if we want a probability of 0.8 of detecting the effect.\nFor many undergraduate students (and researchers in genereal) this is just not plausible. Yet, a lot of studies and dissertations projects obtain significance anyway. In my undergrad stats course I was told that this is evidence for the great magnitude of the effect, i.e. because the power of a test mainly is influenced by the number of participants and the size of the effect, if one is low in a significant study the other must be high - right? In fact this has been the predominant view by some scholars. Recently I stumbled upon this document, a handout by Karl Wuensch, a psychology professor at East Carolina University from his statistics courses in which he states (note that this is dated 2016):\n \u0026hellip;If you were to find a significant effect of the drug with only 25 participants, that would speak to the large effect of the drug. In this case you should not be hesitant to seek publication of your research, but you should be somewhat worried about having it reviewed by “ignorant experts.” Such bozos (and they are to be found everywhere) will argue that your significant results cannot be trusted because your analysis had little power. It is useless to argue with them, as they are totally lacking in understanding of the logic of hypothesis testing. If the editor cannot be convinced that the reviewer is a moron, just resubmit to a different journal and hope to avoid ignorant expert reviewers there.\n Yes, it is true that significance in a small sample would speak to the large effect found, but what Wuensch seems to miss is that it does speak to the large effect in the sample. This does not necessarily (and most probably will not) generalise to the population of interest. Perhaps one is not interested in generalising findings and solely in describing one\u0026rsquo;s sample - however, I think that most would agree that this is not what the majortiy of psychologists want.\nBut why does not the effect we have found in the sample generalise to the population just because we have low power? Well, intuitively, which score on an IMDB film rating would you rather trust, an average of 9/10 given by 5 people or an average of 6/10 given by 100 people? My guess is that most would say the latter - because we put trust in numbers. In science the above example translates to a phenomenon called the winner\u0026rsquo;s curse. That is the tendency to over estimate the effect size in under powered studies, due to the fact that only the studies that happen to draw a sample with a large effect will obtain a significant result. Together with publication biases (i.e. significant studies to a higher extent get published) this can yield a serious inflation of what is thought to be population effect sizes.\nTo demonstrate this it is useful to look at how such overestimation will affect a field \u0026ldquo;in the long run\u0026rdquo;. If we for example look at the inherently low powered field of single case neuropsychology. That is when you compare a single person (often a patient with some brain lesion) against a normative control group, on some normally distributed function - let\u0026rsquo;s say reaction time. What we want to do is to say whether or not this person has a deficit on this function. Naturally, the probability of detecting such a deficit depends on where in the distribution this patient was located prior to the lesion, i.e. the premorbid ability. Look at the expertly drawn picture below for an example:\nAssume a deficit on a this reaction time of ~2 \u0026amp;sigma caused by some lesion – this means that in this lesioned population, a deficit will only be found 50 % of the time (if we operationalise a detection by our patient being 2 \u0026amp;sigma below the population mean), as can be seen in the above illustration. That is, the power of detecting this deficit will never exceed 50 %. A deficit of 2 σ can never cross the critical value if a patient had a premorbid ability above the mean (σ is here the standard deviation). The problem of premorbid ability generalises to group lesion studies as well, but more in the sense that it increases variability that can cloud inferences. This calls for the need of increasing sample sizes which often is cumbersome and, in some cases, impossible in the lesioned populations. So, what would this lead to in the long run? By running simulations of studies (in hundreds of thousands) one can approximate how such bias would affect the overall estimation given specific parameters, like the size of the deficit and the number of people in the control sample. I will include my code for such simulation in this specific field below:\nwin_sim \u0026lt;- function (nsim, deficit, ncon) {\r# Matrix where each row represents observations\r# on a variable from controls plus a patient\rranmat \u0026lt;- matrix(rnorm((ncon + 1) * nsim), nrow = nsim,\rncol = ncon + 1)\r# Induce a deficit on the first obs of each row\r# and compare to the other obs on that row.\r# Save the median of all found deficits.\rmed_def \u0026lt;- median(\rapply(cl, ranmat, 1, function(x) {if (pt(\r((x[1] - def) - mean(x[2:ncon+1]))\r/(sd(x[2:ncon+1])*sqrt(length(x)\r/(length(x) - 1))),\rdf = length(x) - 2)\u0026lt;0.05) {\r(x[1] - def)\r} else { NA } }), na.rm = TRUE)\r# Return the average overestimation\rreturn(- def -med_def) }\r This simulation returns the median overestimation of as many studies as you choose. If you run it for several different parameter combinations (number of controls and size of deficit). In the graph below I have taken the median of 1000 000 simulated single case studies over functional deficits ranging from 1 to 4 standard deviations for 4 different sizes of control groups.\nFigure 1: Median overestimation with Crawford and Howell (1998) method, 10^6^ simulations for every parameter combination.\n\rWhat becomes evident here is that even with a deficit of 2 σ where we would expect a probability of 50 %, we would get a \u0026ldquo;general\u0026rdquo; overestimation of this deficit of about 0.6 σ (which is quite alot). This is due to the fact that we cannot detect the people that have a premobrbid ability above the population mean, if not our control sample by chance happens to be drawn from the \u0026ldquo;right side\u0026rdquo; side of the distribution (that is we draw a control sample with high reaction time abilities).\nThis also explains the curious case when we have a small control sample and a small effect size - yielding a lower overestimation, even though we technically should have lower power. It is easier for a small sample to have a mean that differs from the population mean (think again about the IMDB score), meaning that they can be both higher and lower in an equally distributed manner. However, since our simulated patient solely is diagnosed with a deficit if they have a reaction time that is lower than the control sample mean, this will bias the result in favour of when the control sample are drawn from the right side of the distribution - making it easier to detect smaller deficits and hence the overestimation is lowered.\nWhat else is evident is that the difference in overestimation between a control sample size of 15 and that of 70 is marginal. Meaning that single case researchers would waste their resources collecting data from larger control sample sizes, given that they want to minimise overestimation.\nThis is just one problem that low power yields, and in a very specific field. In the next post I will simulate the effects in more general experiments and talk about other power issues, such as how the positive predictive value is affected. However, I hope that by showing you this, it is clear that low power is not only bad because it will become harder for you to obtain significance in your undergrad thesis. It is bad because, in the long run, it can invalidate our field.\n","date":1584403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584456528,"objectID":"4792175168e1d9fff85491b804896b8f","permalink":"/post/the-curious-case-of-the-winner-s-curse/","publishdate":"2020-03-17T00:00:00Z","relpermalink":"/post/the-curious-case-of-the-winner-s-curse/","section":"post","summary":"Key concepts:\n Power = the probability of finding an effect if the effect is true  Have you ever been at a psychology stats lecture listening to your teacher rambling about \u0026ldquo;power\u0026rdquo;, talking about its importance for your experiment to yield a significant result but without really explaining the \u0026ldquo;why\u0026rdquo; of it all?","tags":["Monte Carlo","Simulation","Power","Winner's Curse"],"title":"The Curious Case of the Winner's Curse","type":"post"},{"authors":["Jonathan Ö. Rittmo"],"categories":null,"content":"","date":1580342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580342400,"objectID":"9923583e57d8142989f6f17fd41262c3","permalink":"/publication/neuropsychdiss/","publishdate":"2020-01-30T00:00:00Z","relpermalink":"/publication/neuropsychdiss/","section":"publication","summary":"The main research questions for this project are: Which are the main statistical methods used in single-case studies over the last ten years? How do the methods compare and what does their power curves look like? Can a multivariate approach to detecting dissociations be developed and would a power advantage to its univariate counterpart be found? Would such method more reliably measure the underlying contructs we believe to have found? To what extent does the winners curse affect neuropsychology? How would the distribution of corrected effect sizes look? All the above form the basis of the more general question how can we improve the validity of neuropsychology?","tags":["Monte Carlo simulations","Hotteling's T2","Dissociation","Power","Winner's Curse"],"title":"Single Case Neuropsychology: validity and reliability in a power-wise pinioned field (work in progress)","type":"publication"},{"authors":["Jonathan Ö. Rittmo"],"categories":null,"content":"","date":1578787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578787200,"objectID":"96c0d24758bab983dbdb7f55b0783b49","permalink":"/publication/statthesis/","publishdate":"2020-01-12T00:00:00Z","relpermalink":"/publication/statthesis/","section":"publication","summary":"A review of the multivariate analysis of variance (MANOVA) along with its appropriateness under various conditions is presented. In particular, the thesis addresses how different covariance structures plausible in brain imaging, and strengths of the correlations between dependent variables in simulated variable systems affect the power of the analysis in relation to various combinations of effect sizes. The aim was to illuminate these relationships and offer insights in contingencies yielding the highest power, aiding researchers in designing powerful experiments. Simulations revealed that the most improbable conditions yielded the highest power, i.e. when effect sizes differed in size and/or direction, but the correlation was highly positive or when the effect sizes and directions were equal but the correlation highly negative. Similar patterns have been demonstrated before (Cole, Maxwell, Arvey, \u0026 Salas, 1994) but the present thesis offers a generalisation, demonstrating that the effect is present for an arbitrary number of dependent variables and groups. Furthermore, it is shown that multivariate analyses exhibit lower power when effect sizes are small as compared to medium even in situations where 6 variables exhibit a small effect compared to 1 of the variables exhibiting a medium effect. Difficulties in controlling the Type 1 error rate are addressed as well.","tags":["Monte Carlo simulations","Power analysis","MANOVA"],"title":"MANOVA and its contingencies: on the relation between power and correlation - Can the utilisation of multivariate analyses alleviate the power crisis in neuropsychology?","type":"publication"},{"authors":["Jonathan Ö. Rittmo","Rickard Carlsson"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"5266342d02d961078b4ab9e34a4e84bb","permalink":"/publication/cogdiss/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/cogdiss/","section":"publication","summary":"A study using an incomplete repeated measures design was performed to investigate whether a construction of other peoples’ associative mappings (in this case stimulus-outcome mappings) in 33 subjects could occur when observing another person’s facial expression while they perform a conditional discrimination task with differential value-based outcomes, and if such construction could facilitate the subjects’ own learning when afterwards performing the same task. Through this, providing evidence for the use of such constructions as a mechanism aiding individuals engaged in joint activities, including so called joint action. A significantly better performance was observed when such construction was possible in comparison with a condition where it was not, indicating that the construction of others’ associative mappings do occur, at least in conditional discrimination tasks. To further strengthen the indication that better performance was due to construction of the other’s associ- ative mappings and that this construction emerged due to social processing, EEG activity was measured during the task and compared to activity measured during a similar, though non-social, task. Oscillatory differences in EEG between conditions was used as an index of social perception. Differences in power/synchronisation over the alpha, beta and mu band between the conditions were analysed. All bands showed a significant increase in power in the social condition, although mu was expected to show the reversed pattern. Alpha increase may suggest inhibition of the self-perspective and beta increase could be related to processing of emotionally valanced stimuli or use of executive functions – both results may indicate that the social condition was perceived as social.","tags":["EEG","Frequency band analysis","Differential Oucomes Effect","Operant Learning","Forced Choice task","Emotional Contagion"],"title":"Oscillatory Differences in EEG - An index for social processing? A social affective perspective on the associative two-process theory of the differential outcomes effect","type":"publication"}]