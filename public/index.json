[{"authors":["admin"],"categories":null,"content":"Brain damaged brain student writing about methodological and statistical issues in cognitive neuroscience, as well as other related topics. If I feel inclined I might write more technical posts and if you\u0026rsquo;re real unlucky there might even slip in some fiction book reviews. I will only post about my mental fatigue when I have the energy.\n","date":1602720000,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1602720000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Brain damaged brain student writing about methodological and statistical issues in cognitive neuroscience, as well as other related topics. If I feel inclined I might write more technical posts and if you\u0026rsquo;re real unlucky there might even slip in some fiction book reviews.","tags":null,"title":"Jonathan Rittmo","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Tutorials on my upcoming R package for single case research will be uploaded shortly.","tags":null,"title":"","type":"docs"},{"authors":["Robert D McIntosh","Jonathan Rittmo"],"categories":null,"content":"","date":1602720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602720000,"objectID":"edf4e016b1da084fc331f3014b010836","permalink":"/publication/power_primer/","publishdate":"2020-09-03T00:00:00Z","relpermalink":"/publication/power_primer/","section":"publication","summary":"Researchers and clinicians in neuropsychology often compare individual patients against healthy control samples, to quantify evidence for cognitive-behavioural deficits and dissociations.  Statistical methods for these comparisons have been developed that control Type I (false positive) errors effectively. However, remark-ably little attention has been given to the power of these tests. In this practical primer, we describe, in minimally technical terms, the origins and limits of power for case-control comparisons. We argue that power calculations can play useful roles in single-case study design and interpretation, and we make suggestions for optimising power in practice.  As well as providing figures, tables and tools for estimating the power of case-control comparisons, we hope to assist researchers insetting realistic expectations for what such tests can achieve in general.","tags":["affect","differential outcomes training","inference","knowledge transfer"],"title":"Power calculations in single-case neuropsychology: a practical primer","type":"publication"},{"authors":["Jonathan Rittmo","Rickard Carlsson","Pierre Gander","Robert Lowe"],"categories":null,"content":"","date":1597017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597017600,"objectID":"3c352b4d865a8c2f89fdd5d6674e0ceb","permalink":"/publication/vic_value/","publishdate":"2020-08-10T00:00:00Z","relpermalink":"/publication/vic_value/","section":"publication","summary":"The findings of differential outcomes training procedures in controlled stimulus-response learning settings have been explained through theorizing two processes of response control. These processes concern: i) a stimulus-response route, and, ii) an outcome expectancy route through which valuations of stimuli (typically auditory or visual) may be represented. Critically, under certain contingencies of learning, the interaction of these two processes enables a transfer of knowledge. Transfer is hypothesized to occur via implicit inference for response selection given novel stimulus-response pairings. In this article, we test this transfer of knowledge, previously only examined in individual settings, in novel social settings. We find that participants are able to achieve transfer of knowledge and suggest they achieve this through vicariously learning the differential valuations of stimuli made by the (confederate) ‘other’ involved in the task. We test this effect under two experimental conditions through manipulation of the information made available to participants observing the confederate other's choices. The results of EEG recordings are, additionally, evaluated and discussed in the context of social signalling and emotional and cognitive empathy. We also consider implications for clinical and technological social learning settings.","tags":["affect","differential outcomes training","inference","knowledge transfer"],"title":"Vicarious Value Learning: Knowledge Transfer through Affective Processing on a Social Differential Outcomes Task","type":"publication"},{"authors":[],"categories":[],"content":"\r\r\r…external perception is an internal dream which proves to be in harmony with external things; and instead of calling hallucination a false external perception, we must call external perception true hallucination.\n\rThe above quote from 19th century philospher Hippolyte Taine captures the elusive question: what do we mean by ‘reality’? If you recognise the featured image, you have probably come across the game Hellblade: Senuas Sacrifice, where you follow Senua battle the cracking of her reality. The game was critically acclaimed for depicting the subjective experience of psychosis.\nThe game makers worked closely with neuroscientists, one of which was Paul Fletcher, a professor at Cambridge who has devoted much of his career to understanding the mechanisms of this disorder. I attended a talk of his a couple of months ago where he mentioned the game which immediately spiked my interest. Due to the current circumstances I had the chance to play through it this weekend - and it was a ride. I know my last post said I was gonna write more about power curves but after playing the game I couldn’t resist a small post on this subject. A version of Fletcher’s talk, in which he conveys the keystone ideas from his 20 years of research is available here.\nTo get as immersed as possible I played the game in complete darkness, with noise cancelling headphones and the volume high (which I sincerly recommend, since they put a lot of effort in to the audio). I nearly completed it in one sitting which also was prefereable for screening off as much of my world as possible and delve into that of Senua’s psychosis. In this post I am going to go through some of the ideas they based the game on from Fletcher’s research ‒ which really shines through in both script and experience.\nThe term ‘psychosis’ is not uncontroversial. If we define it loosely as losing contact with reality, it is easy to see why. Because what makes our healthy perception real? Fletcher makes the case that we are all a bit out of touch with reality. Most people simply hallucinate true events.\nThis might be difficult to grasp. But since your brain is encased in a skull and has no direct contact with the outside world it must create a predictive model of it. Hence, Fletcher argues, psychotic illness is just a small variation in normal perceptive processing.\nWhy do we have a brain? A fundemental fact of biological life is that the genes that most easily continue to exist tend to do just that. In a complex and noisy world, a machine that can make predictions about it would benefit any organism.\nIn a sense then, our brain is like a scientist, trying to draw inferences and make predictions from incomplete data. To do this one utilises expectations. Information from previous experiences that make our predictions more or less likely. If our predictions do not match the external world we must update them (in science and in life) with the given feedback. One can imagine the power of such device just by looking at how science has benefitted society.\nThis creates loops of predictions, inputs and prediction errors that integrate to form a stable perception. It is a breakdown in these integration processes that causes the psychotic state, Fletcher argues.\nPerception has two foundations: input and predictions. Take a look at the hollow mask illusion:\nIn the bottommost image we see a convex surface. The facial features however, make us expect it to be concave. Therefore it appears as such. It is easy to imagine how more abstract ideas could shape perceived input as well. For example, facial expressions being interpreted differently depending on contexts.\nThis mechanism can also be additive. Take the Kanizsa triangle, for example, where it is almost impossible not to see a white triangle laying over the other shapes even though it is not there:\nSo, expectations create perceptions. Fletcher describes a system that tries to maintain stability between predictions and input. To best align your internal world with the external. This happens at multiple levels ‒ from abstract (expressions) to concrete (Kanizsa triangle). Below is my interpretation of this system, W = weight.\nYou can see that a balance between input and predictions must be maintained. If one gets too weighted it affects perception. For example if the input is cut off, predictions get an overbalance and hence your mind takes control of your perception and hallucinations might be induced - which often happen during e.g. sensory deprivation.\nFletcher also mention that traumatic experiences, such as child abuse, could cause abstract predictions being unreasonably weighted. E.g. predicting low self worth could in a downstream manner affect how you see and interpret aspects of the world. Perhaps it would seem more ill-willed. Similarily such prediction might cause additive percepts of, for example, derogatory voices. This would correspond to the two cornerstones of pyschosis, delusion and hallucination respectively.\nPsychotic traits is, by this model, hence formed by too strong predictions. But strong predictions can also aid your perception. Imagine looking at a painting in your home during night. Since you know it, it’s easier to see the contours, right? If you don’t believe me, try to discern the image below:\nNot very easy, right? I, however, cannot not see myself as a kid:\nGiven Fletcher’s model, hallucination prone individuals would thus be better at these types of tasks (given previous exposure, so that they have something to expect). This was also found by him and colleagues.\nFurther evidence both for and against the model is reviewed in the talk. But I do not want to spoil all the fun and advise you to take a look at it.\nI should also make it clear that Fletcher does not claim that this model paint a complete picture. I for one am a bit sceptical about the hierarchical structure of the integration processes. However, if you are interested in this stuff (who wouldn’t be interested in what reality is, eh?) Fletcher makes a compelling case. Playing through Hellblade after you’ve watched the talk makes it even more compelling as the ideas are communicated by experiencing them ‒ which is both thought provoking and generates an understanding and compassion for the people suffering from this. (You could also use drugs, but I’d give Hellblade a go first).\n","date":1586563200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586611974,"objectID":"090ed38b0c6e87806dc384926f07db2b","permalink":"/post/perception-and-psychosis/","publishdate":"2020-04-11T00:00:00Z","relpermalink":"/post/perception-and-psychosis/","section":"post","summary":"…external perception is an internal dream which proves to be in harmony with external things; and instead of calling hallucination a false external perception, we must call external perception true hallucination.","tags":[],"title":"Perception, Psychosis and Hellblade","type":"post"},{"authors":[],"categories":["research"],"content":"Key concepts:\n Power = the probability of finding an effect if the effect is true  Have you ever been at a psychology stats lecture listening to your teacher rambling about \u0026ldquo;power\u0026rdquo;, talking about its importance for your experiment to yield a significant result but without really explaining the \u0026ldquo;why\u0026rdquo; of it all? Well, so have I. It is usually easy enough to grasp that low power = bad, high power = good - it\u0026rsquo;s name kind of gives it away. And given that significance is often treated as the holy grail in psychology most students would want a high probability to obtain it. The advice is often to calculate a sample size based on some previous (or just predicted) effect. However, for a two group experiment with a between group design and expected medium effect (which arguably could be seen as optimistic) we would need 64 participants if we want a probability of 0.8 of detecting the effect.\nFor many undergraduate students (and researchers in genereal) this is just not plausible. Yet, a lot of studies and dissertations projects obtain significance anyway. In my undergrad stats course I was told that this is evidence for the great magnitude of the effect, i.e. because the power of a test mainly is influenced by the number of participants and the size of the effect, if one is low in a significant study the other must be high - right? In fact this has been the predominant view by some scholars. Recently I stumbled upon this document, a handout by Karl Wuensch, a psychology professor at East Carolina University from his statistics courses in which he states (note that this is dated 2016):\n \u0026hellip;If you were to find a significant effect of the drug with only 25 participants, that would speak to the large effect of the drug. In this case you should not be hesitant to seek publication of your research, but you should be somewhat worried about having it reviewed by “ignorant experts.” Such bozos (and they are to be found everywhere) will argue that your significant results cannot be trusted because your analysis had little power. It is useless to argue with them, as they are totally lacking in understanding of the logic of hypothesis testing. If the editor cannot be convinced that the reviewer is a moron, just resubmit to a different journal and hope to avoid ignorant expert reviewers there.\n Yes, it is true that significance in a small sample would speak to the large effect found, but what Wuensch seems to miss is that it does speak to the large effect in the sample. This does not necessarily (and most probably will not) generalise to the population of interest. Perhaps one is not interested in generalising findings and solely in describing one\u0026rsquo;s sample - however, I think that most would agree that this is not what the majortiy of psychologists want.\nBut why does not the effect we have found in the sample generalise to the population just because we have low power? Well, intuitively, which score on an IMDB film rating would you rather trust, an average of 9/10 given by 5 people or an average of 6/10 given by 100 people? My guess is that most would say the latter - because we put trust in numbers. In science the above example translates to a phenomenon called the winner\u0026rsquo;s curse. That is the tendency to over estimate the effect size in under powered studies, due to the fact that only the studies that happen to draw a sample with a large effect will obtain a significant result. Together with publication biases (i.e. significant studies to a higher extent get published) this can yield a serious inflation of what is thought to be population effect sizes.\nTo demonstrate this it is useful to look at how such overestimation will affect a field \u0026ldquo;in the long run\u0026rdquo;. If we for example look at the inherently low powered field of single case neuropsychology. That is when you compare a single person (often a patient with some brain lesion) against a normative control group, on some normally distributed ability - let\u0026rsquo;s say IQ. What we want to do is to say whether or not this person has a deficit on this function. Naturally, the probability of detecting such a deficit depends on where in the distribution this patient was located prior to the lesion, i.e. the premorbid ability. Look at the expertly drawn picture below for an example:\nAssume a deficit on IQ of ~2 \u0026amp;sigma caused by some lesion – this means that in this lesioned population, a deficit will only be found 50 % of the time (if we operationalise a detection by our patient being 2 \u0026amp;sigma below the population mean), as can be seen in the above illustration. That is, the power of detecting this deficit will never exceed 50 %. A deficit of 2 σ can never cross the critical value if a patient had a premorbid ability above the mean (σ is here the standard deviation). The problem of premorbid ability generalises to group lesion studies as well, but more in the sense that it increases variability that can cloud inferences. This calls for the need of increasing sample sizes which often is cumbersome and, in some cases, impossible in the lesioned populations. So, what would this lead to in the long run? By running simulations of studies (in hundreds of thousands) one can approximate how such bias would affect the overall estimation given specific parameters, like the size of the deficit and the number of people in the control sample. I will include my code for such simulation in this specific field below:\nwin_sim \u0026lt;- function (nsim, deficit, ncon) {\r# Matrix where each row represents observations\r# on a variable from controls plus a patient\rranmat \u0026lt;- matrix(rnorm((ncon + 1) * nsim), nrow = nsim,\rncol = ncon + 1)\r# Induce a deficit on the first obs of each row\r# and compare to the other obs on that row.\r# Save the median of all found deficits.\rmed_def \u0026lt;- median(\rapply(cl, ranmat, 1, function(x) {if (pt(\r((x[1] - def) - mean(x[2:ncon+1]))\r/(sd(x[2:ncon+1])*sqrt(length(x)\r/(length(x) - 1))),\rdf = length(x) - 2)\u0026lt;0.05) {\r(x[1] - def)\r} else { NA } }), na.rm = TRUE)\r# Return the average overestimation\rreturn(- def -med_def) }\r This simulation returns the median overestimation of as many studies as you choose. If you run it for several different parameter combinations (number of controls and size of deficit). In the graph below I have taken the median of 1000 000 simulated single case studies over functional deficits ranging from 1 to 4 standard deviations for 4 different sizes of control groups.\nFigure 1: Median overestimation with Crawford and Howell (1998) method, 10^6^ simulations for every parameter combination.\n\rWhat becomes evident here is that even with a deficit of 2 σ where we would expect a probability of 50 %, we would get a \u0026ldquo;general\u0026rdquo; overestimation of this deficit of about 0.6 σ (which is quite alot). This is due to the fact that we cannot detect the people that have a premobrbid ability above the population mean, if not our control sample by chance happens to be drawn from the \u0026ldquo;right side\u0026rdquo; side of the distribution (that is we draw a control sample with high IQ).\nThis also explains the curious case when we have a small control sample and a small effect size - yielding a lower overestimation, even though we technically should have lower power. It is easier for a small sample to have a mean that differs from the population mean (think again about the IMDB score), meaning that they can be both higher and lower in an equally distributed manner. However, since our simulated patient solely is diagnosed with a deficit if they have an IQ lower than the control sample mean, this will bias the result in favour of when the control sample are drawn from the right side of the distribution - making it easier to detect smaller deficits and hence the overestimation is lowered.\nWhat else is evident is that the difference in overestimation between a control sample size of 15 and that of 70 is marginal. Meaning that single case researchers would waste their resources collecting data from larger control sample sizes, given that they want to minimise overestimation.\nThis is just one problem that low power yields, and in a very specific field. In the next post I will simulate the effects in more general experiments and talk about other power issues, such as how the positive predictive value is affected. However, I hope that by showing you this, it is clear that low power is not only bad because it will become harder for you to obtain significance in your undergrad thesis. It is bad because, in the long run, it can invalidate our field.\n","date":1584403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584456528,"objectID":"4792175168e1d9fff85491b804896b8f","permalink":"/post/the-curious-case-of-the-winner-s-curse/","publishdate":"2020-03-17T00:00:00Z","relpermalink":"/post/the-curious-case-of-the-winner-s-curse/","section":"post","summary":"Key concepts:\n Power = the probability of finding an effect if the effect is true  Have you ever been at a psychology stats lecture listening to your teacher rambling about \u0026ldquo;power\u0026rdquo;, talking about its importance for your experiment to yield a significant result but without really explaining the \u0026ldquo;why\u0026rdquo; of it all?","tags":["Monte Carlo","Simulation","Power","Winner's Curse"],"title":"The Curious Case of the Winner's Curse","type":"post"},{"authors":["Jonathan Rittmo"],"categories":null,"content":"","date":1580342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580342400,"objectID":"9923583e57d8142989f6f17fd41262c3","permalink":"/publication/neuropsychdiss/","publishdate":"2020-09-13T00:00:00Z","relpermalink":"/publication/neuropsychdiss/","section":"publication","summary":"Single case studies where a brain damaged patient is compared to a normative control group have historically been crucial for neuropsychology. Some authors have argued that the methodology is fundamentally flawed, others that it is the only way to draw valid inferences of cognition. Whether the case, the usage of the method has declined. Reasons for this might be several but difficulties in working with a clinical population and publication pressures have been cited as possible culprits. This is while statistical methods for the paradigm have been appropriately refined and developed, mainly by John Crawford and Paul Garthwaite, during the last 22 years. These methods have given a field often viewed as “merely anecdotal” a much needed rigour. The present work first aims to evaluate these tools with regards to statistical power, keeping with the increased focus on power for evaluating validity of scientific fields. In general power was, unexpectedly, found to be low. Low power is known to generate consistent overestimations of effect sizes, so the extent to which such error estimation is affecting the field was quantified and correction methods suggested. Secondly, to encourage the use of the refined tools developed, the present work aims to make them more accessible by i) implementing recommended hypothesis tests along with power calculators in an R package: `singcar` ii) providing a basic conceptual intuition behind the need for their development. Lastly, the future of single case neuropsychology is discussed.","tags":["Monte Carlo simulations","winner’s curse bias correction","statistical power","Winner's Curse","single case neuropsychology"],"title":"Single case neuropsychology: Validity of hypothesis testing in a power-wise pinioned field","type":"publication"},{"authors":["Jonathan Rittmo"],"categories":null,"content":"","date":1578787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578787200,"objectID":"96c0d24758bab983dbdb7f55b0783b49","permalink":"/publication/statthesis/","publishdate":"2020-01-12T00:00:00Z","relpermalink":"/publication/statthesis/","section":"publication","summary":"A review of the multivariate analysis of variance (MANOVA) along with its appropriateness under various conditions is presented. In particular, the thesis addresses how different covariance structures plausible in brain imaging, and strengths of the correlations between dependent variables in simulated variable systems affect the power of the analysis in relation to various combinations of effect sizes. The aim was to illuminate these relationships and offer insights in contingencies yielding the highest power, aiding researchers in designing powerful experiments. Simulations revealed that the most improbable conditions yielded the highest power, i.e. when effect sizes differed in size and/or direction, but the correlation was highly positive or when the effect sizes and directions were equal but the correlation highly negative. Similar patterns have been demonstrated before (Cole, Maxwell, Arvey, \u0026 Salas, 1994) but the present thesis offers a generalisation, demonstrating that the effect is present for an arbitrary number of dependent variables and groups. Furthermore, it is shown that multivariate analyses exhibit lower power when effect sizes are small as compared to medium even in situations where 6 variables exhibit a small effect compared to 1 of the variables exhibiting a medium effect. Difficulties in controlling the Type 1 error rate are addressed as well.","tags":["Monte Carlo simulations","Power analysis","MANOVA"],"title":"MANOVA and its contingencies: on the relation between power and correlation - Can the utilisation of multivariate analyses alleviate the power crisis in neuropsychology?","type":"publication"},{"authors":["Jonathan Rittmo","Rickard Carlsson"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"5266342d02d961078b4ab9e34a4e84bb","permalink":"/publication/cogdiss/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/cogdiss/","section":"publication","summary":"A study using an incomplete repeated measures design was performed to investigate whether a construction of other peoples’ associative mappings (in this case stimulus-outcome mappings) in 33 subjects could occur when observing another person’s facial expression while they perform a conditional discrimination task with differential value-based outcomes, and if such construction could facilitate the subjects’ own learning when afterwards performing the same task. Through this, providing evidence for the use of such constructions as a mechanism aiding individuals engaged in joint activities, including so called joint action. A significantly better performance was observed when such construction was possible in comparison with a condition where it was not, indicating that the construction of others’ associative mappings do occur, at least in conditional discrimination tasks. To further strengthen the indication that better performance was due to construction of the other’s associ- ative mappings and that this construction emerged due to social processing, EEG activity was measured during the task and compared to activity measured during a similar, though non-social, task. Oscillatory differences in EEG between conditions was used as an index of social perception. Differences in power/synchronisation over the alpha, beta and mu band between the conditions were analysed. All bands showed a significant increase in power in the social condition, although mu was expected to show the reversed pattern. Alpha increase may suggest inhibition of the self-perspective and beta increase could be related to processing of emotionally valanced stimuli or use of executive functions – both results may indicate that the social condition was perceived as social.","tags":["EEG","Frequency band analysis","Differential Oucomes Effect","Operant Learning","Forced Choice task","Emotional Contagion"],"title":"Oscillatory Differences in EEG - An index for social processing? A social affective perspective on the associative two-process theory of the differential outcomes effect","type":"publication"}]